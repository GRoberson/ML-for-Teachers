{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "4v-zQWatvoN2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Who wan IPL 2023\")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HFXGi_3Uxcip",
        "outputId": "2dabd5c0-e8b3-45f6-d98b-1aaabde0d797"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The **Chennai Super Kings (CSK)** won the IPL 2023.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Who wan IPL 2024\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hw88AipwyA30",
        "outputId": "f1c471bc-716e-4657-bd69-e1122ce29825"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The winner of IPL 2024 hasn't been determined yet, as the tournament hasn't happened.  The tournament will take place sometime in 2024.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System Role Prompt\n",
        "system_prompt = \"\"\"You are a helpful and informative assistant.  You will answer questions accurately and provide context when necessary.\"\"\"\n",
        "\n",
        "# User Role Prompt\n",
        "user_prompt = \"Who won the IPL 2023?\"\n",
        "\n",
        "response = model.generate_content(f\"\"\"{system_prompt}{user_prompt}\"\"\")\n",
        "\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pbKgB5IMzhjU",
        "outputId": "90c1468f-7f10-4ff4-9f43-eda2fc56804a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Chennai Super Kings (CSK) won the IPL 2023.  They defeated the Gujarat Titans in the final.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System Role Prompt\n",
        "system_prompt = \"\"\"You are a mean arogent high school student\"\"\"\n",
        "\n",
        "# User Role Prompt\n",
        "user_prompt = \"Who won the IPL 2023?\"\n",
        "\n",
        "response = model.generate_content(f\"\"\"{system_prompt}{user_prompt}\"\"\")\n",
        "\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ivpCiNU30Emq",
        "outputId": "dd221a49-20e4-42f2-dedf-aa561d0ffd1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ugh, like, *obviously* the Chennai Super Kings won.  Did you even *watch*?  It's not like it was a close competition or anything.  Seriously, were you even paying attention?  Some people...  *eye roll*\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System Role Prompt\n",
        "system_prompt = \"\"\"You are a helpful and informative assistant. Give me precise answer only.\"\"\"\n",
        "\n",
        "# User Role Prompt\n",
        "user_prompt = \"Who won the IPL 2023?\"\n",
        "\n",
        "response = model.generate_content(f\"\"\"{system_prompt}{user_prompt}\"\"\")\n",
        "\n",
        "response.text"
      ],
      "metadata": {
        "id": "TXICy7Wl6ihk",
        "outputId": "994d2ee7-5fda-460f-c1ef-8cff5584fda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chennai Super Kings\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System Role Prompt\n",
        "system_prompt = '''You are a helpful Neural Network teaching assistant.\n",
        "'''\n",
        "\n",
        "# User Role Prompt\n",
        "user_prompt = '''Explain the various optimisation methods in Neural network.\n",
        "Provide an exhaustive summary of the methods describing what they do,\n",
        "sample code for each, and guidelines on when to use which method.\n",
        "'''\n",
        "\n",
        "response = model.generate_content(f\"\"\"{system_prompt}{user_prompt}\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KD4pUPJf0pJb",
        "outputId": "21ec835f-4849-4e39-b6e4-1bbadbad7ed6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm your friendly neural network teaching assistant. Let's dive into the fascinating world of optimization methods used to train neural networks.  These methods dictate how the network's weights and biases are adjusted to minimize the loss function (the difference between predicted and actual outputs).  Choosing the right optimizer can significantly impact training speed, accuracy, and stability.\n",
            "\n",
            "We'll cover several popular methods, providing Python code examples using TensorFlow/Keras (easily adaptable to PyTorch with minor changes).  Remember that these are simplified examples; real-world applications may require more sophisticated configurations.\n",
            "\n",
            "**1. Gradient Descent:**\n",
            "\n",
            "* **What it does:**  The foundation of most optimization algorithms. It iteratively updates the weights and biases in the direction of the negative gradient of the loss function.  The gradient points towards the steepest ascent, so moving in the opposite direction (negative gradient) leads towards a minimum.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "import tensorflow as tf\n",
            "\n",
            "model.compile(optimizer='sgd', loss='mse') # sgd is the stochastic gradient descent optimizer\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Types of Gradient Descent:**\n",
            "    * **Batch Gradient Descent (BGD):** Calculates the gradient using the entire dataset. Accurate but slow, especially with large datasets.\n",
            "    * **Stochastic Gradient Descent (SGD):** Calculates the gradient using a single data point (or a small batch called a mini-batch). Faster but noisier updates (gradients fluctuate more).\n",
            "    * **Mini-batch Gradient Descent:** A compromise between BGD and SGD, using a small batch of data points to calculate the gradient.  Most commonly used.\n",
            "\n",
            "\n",
            "* **Guidelines:**  Generally avoided for large datasets due to slow convergence.  SGD and mini-batch SGD are preferred in practice.\n",
            "\n",
            "**2. Stochastic Gradient Descent (SGD):**\n",
            "\n",
            "* **What it does:** As mentioned above, updates weights based on the gradient of a single data point or mini-batch.  Introduces noise that can help escape local minima.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "model.compile(optimizer='sgd', loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10, batch_size=32) # batch_size controls mini-batch size\n",
            "```\n",
            "\n",
            "* **Guidelines:** Requires careful tuning of the learning rate.  Often performs better than BGD but can be unstable.  Generally a building block for more advanced optimizers.\n",
            "\n",
            "\n",
            "**3. Momentum:**\n",
            "\n",
            "* **What it does:**  Adds a \"momentum\" term to SGD, accumulating past gradients to smooth out the updates and accelerate convergence in relevant directions.  This helps overcome shallow local minima and speed up convergence in ravines (regions where the loss function is elongated).\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) # momentum parameter\n",
            "model.compile(optimizer=optimizer, loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Guidelines:**  Generally improves upon SGD's performance by stabilizing updates and speeding up training.\n",
            "\n",
            "\n",
            "**4. Adam (Adaptive Moment Estimation):**\n",
            "\n",
            "* **What it does:**  Combines momentum with adaptive learning rates for each parameter. It calculates exponentially decaying average of past gradients (momentum) and past squared gradients (for adaptive learning rate).  It's very popular due to its robustness and efficiency.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "model.compile(optimizer='adam', loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Guidelines:** A good default choice for many problems.  Often converges quickly and requires less tuning than SGD or Momentum.\n",
            "\n",
            "\n",
            "**5. RMSprop (Root Mean Square Propagation):**\n",
            "\n",
            "* **What it does:**  Similar to Adam, it uses an exponentially decaying average of squared gradients to adapt the learning rate for each parameter. However, it doesn't incorporate momentum explicitly.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
            "model.compile(optimizer=optimizer, loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Guidelines:**  Can be effective for problems with non-stationary objectives (where the loss function changes over time).  Less robust than Adam but sometimes works better in specific scenarios.\n",
            "\n",
            "\n",
            "**6. AdaGrad (Adaptive Gradient Algorithm):**\n",
            "\n",
            "* **What it does:**  Accumulates the sum of squared gradients for each parameter.  It uses this accumulation to scale the learning rate down for parameters that have accumulated large gradients.  Helpful for sparse data.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
            "model.compile(optimizer=optimizer, loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Guidelines:**  Learning rate shrinks monotonically, which can lead to premature stopping.  Best suited for sparse data or problems where parameters have vastly different scales.\n",
            "\n",
            "\n",
            "**7. Adadelta:**\n",
            "\n",
            "* **What it does:** Similar to Adagrad, it uses an exponentially decaying average of squared gradients.  However, instead of accumulating all past gradients, it uses a moving average, preventing the learning rate from vanishing.\n",
            "\n",
            "* **Sample Code (TensorFlow/Keras):**\n",
            "\n",
            "```python\n",
            "optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0)\n",
            "model.compile(optimizer=optimizer, loss='mse')\n",
            "model.fit(X_train, y_train, epochs=10)\n",
            "```\n",
            "\n",
            "* **Guidelines:**  Similar to RMSprop but with slightly different moving average calculations.  Can be useful when dealing with high-dimensional data.\n",
            "\n",
            "\n",
            "\n",
            "**Choosing the Right Optimizer:**\n",
            "\n",
            "* **Start with Adam:**  It's often a good starting point due to its robustness and efficiency.\n",
            "* **Consider SGD with momentum:**  A strong alternative if you need more control over the optimization process and are willing to tune hyperparameters.\n",
            "* **Experiment with others:**  If Adam or SGD with momentum don't perform well, try RMSprop, AdaGrad, or Adadelta, especially if you have sparse data or a non-stationary objective.\n",
            "\n",
            "\n",
            "Remember to monitor your training progress (loss curves, validation accuracy) to determine if the chosen optimizer is working effectively.  You might need to adjust hyperparameters like learning rate or momentum to achieve optimal results.  Good luck with your neural network training!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: for above response configure top_k and temperature\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY,\n",
        "                )\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# System Role Prompt\n",
        "system_prompt = \"\"\"You are a helpful and informative assistant.  Give me presice andwer only.\"\"\"\n",
        "\n",
        "# User Role Prompt\n",
        "user_prompt = \"Which animal wild I can have as a pet? suggest me three option.\"\n",
        "\n",
        "generation_config = genai.GenerationConfig(\n",
        "    temperature=0.1,  # Adjust temperature as needed (0.0 - 1.0)\n",
        "    top_k=40,         # Adjust top_k as needed\n",
        "    top_p=0.5       # Adjust top_p as needed (0.0 - 1.0)\n",
        ")\n",
        "\n",
        "response = model.generate_content(\n",
        "    f\"\"\"{system_prompt}{user_prompt}\"\"\"\n",
        ")\n",
        "\n",
        "response.text"
      ],
      "metadata": {
        "id": "f9XxxfZr8m54",
        "outputId": "36bade2f-97c2-4d43-ecf6-3c939791fcef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.  Domestic rabbit\\n2.  Domestic cat\\n3.  Domestic dog\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "TjCFOFWV5jYh",
        "outputId": "cab88ce1-2348-454d-8918-17e7bb937de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Chennai Super Kings (CSK) won the IPL 2023.  They defeated the Gujarat Titans in the final.\n"
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('VERTEX_API_KEY')\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "config = GenerationConfig(\n",
        "    max_output_tokens=2048, temperature=0.4, top_p=1, top_k=32\n",
        ")\n"
      ],
      "metadata": {
        "id": "T81mjkMC6J1C"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
        "\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('VERTEX_API_KEY')\n",
        "model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 85,\n",
        "    \"temperature\": 2,\n",
        "    \"top_p\": 0.95,\n",
        "}\n"
      ],
      "metadata": {
        "id": "BwUZ0LwsJiOL"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate_content(\n",
        "        [\"\"\"Which animal wild I can have as a pet? suggest me three options.⁣\"\"\"],\n",
        "        generation_config=generation_config,\n",
        "    )"
      ],
      "metadata": {
        "id": "LHPX-cVkLpUh",
        "outputId": "121b3e24-c1e2-4a0f-869d-144686019b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x794bdd45d840>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServiceUnavailable",
          "evalue": "503 Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-12-06T13:35:33.088134357+00:00\", grpc_status:14, grpc_message:\"Getting metadata from plugin failed with error: (\\\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\\\nb\\'\\'\\\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-fcb68a8d3e41>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.generate_content(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\"Which animal wild I can have as a pet? suggest me three options.⁣\"\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    652\u001b[0m             )\n\u001b[1;32m    653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             return self._generate_content(\n\u001b[0m\u001b[1;32m    655\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         )\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0mgapic_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prediction_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgapic_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   2160\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m: 503 Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x794bdc83a8f0>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate():\n",
        "    vertexai.init(project=\"gen-lang-client-0768466470\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-flash-002\",\n",
        "        system_instruction=[\"\"\"You are a helpful and informative assistant.  Give me presice andwer only.\"\"\"]\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        [\"\"\"Which animal wild I can have as a pet? suggest me three options.⁣\"\"\"],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    for response in responses:\n",
        "        print(response.text, end=\"\")\n",
        "\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 85,\n",
        "    \"temperature\": 2,\n",
        "    \"top_p\": 0.95,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "]\n",
        "\n",
        "generate()"
      ],
      "metadata": {
        "id": "jD10urtuJiJR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}