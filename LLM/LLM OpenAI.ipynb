{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "mBdCgR9efxf_",
        "outputId": "0bac9062-bdd3-41ec-ca72-2d8371a990b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "rHT4bfzngDrk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won IPL 2020\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "ysVSvh8sgj0I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai.api_key = \"hadjkshfkjdafk jdhfkjadhfkjadhkf\"\n",
        "from google.colab import userdata # import to use Colab Credential\n",
        "\n",
        "openai.api_key=userdata.get('OPENAI_API_KEY') # Get your API Key"
      ],
      "metadata": {
        "id": "gEv-xgJvgkNc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-16k\",\n",
        "  messages=messages\n",
        ")"
      ],
      "metadata": {
        "id": "vwr2g8stgnwt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response"
      ],
      "metadata": {
        "id": "GpxFnmYfhJQA",
        "outputId": "984a8d69-7319-4edc-c6b7-c8539262128b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-AbliZ3ClyBvpdmBtCe5gqknrayizB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Mumbai Indians won the Indian Premier League (IPL) in 2020.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1733564927, model='gpt-3.5-turbo-16k-0613', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=23, total_tokens=40, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "OJ_wpVgXhLmU",
        "outputId": "cdbb9a3a-4e23-4a26-8e5d-0add470de4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Mumbai Indians won the Indian Premier League (IPL) in 2020.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"user\", \"content\": \"You are a very helpfull assistant. Who won IPL 2020\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "pCS_3vFvhRLL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-16k\",\n",
        "  messages=messages\n",
        ")\n",
        "chat_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "UOn585yOheMA",
        "outputId": "1b3b3eab-72cf-40d0-fbba-36de0112d72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mumbai Indians won IPL 2020.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''You are a helpful Neural Network teaching assistant.\n",
        "Explain the various optimisation methods in Neural network.\n",
        "Provide an exhaustive summary of the methods describing what they do,\n",
        "sample code for each, and guidelines on when to use which method.\n",
        "'''\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]"
      ],
      "metadata": {
        "id": "6WpJoVZwhhSR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=message,\n",
        "    max_tokens=800,\n",
        "    temperature=0.5,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0)\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "VrKEEomKhvzF",
        "outputId": "447714ae-5ebd-4eb1-af06-e963c07dc4b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several optimization methods commonly used in neural networks to train models effectively. Here is an exhaustive summary of some of these methods, along with sample code and guidelines on when to use each method:\n",
            "\n",
            "1. Gradient Descent (GD):\n",
            "   - Description: GD is a basic optimization method that iteratively updates the model parameters in the direction of the steepest descent of the loss function.\n",
            "   - Sample code (using TensorFlow):\n",
            "     ```python\n",
            "     optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
            "     with tf.GradientTape() as tape:\n",
            "         loss = model(x_train, y_train)\n",
            "     gradients = tape.gradient(loss, model.trainable_variables)\n",
            "     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
            "     ```\n",
            "   - Guidelines: GD is suitable for small datasets or simple models. It can be slow for large datasets or complex models due to computing gradients for the entire dataset.\n",
            "\n",
            "2. Stochastic Gradient Descent (SGD):\n",
            "   - Description: SGD is an extension of GD that updates the model parameters using gradients computed on a randomly selected subset of the training data (batch).\n",
            "   - Sample code (using TensorFlow):\n",
            "     ```python\n",
            "     optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
            "     for epoch in range(num_epochs):\n",
            "         for batch_x, batch_y in train_dataset:\n",
            "             with tf.GradientTape() as tape:\n",
            "                 loss = model(batch_x, batch_y)\n",
            "             gradients = tape.gradient(loss, model.trainable_variables)\n",
            "             optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
            "     ```\n",
            "   - Guidelines: SGD is suitable for large datasets as it reduces computational cost per iteration. However, it can have high variance in convergence due to the random selection of batches.\n",
            "\n",
            "3. Mini-Batch Gradient Descent:\n",
            "   - Description: Mini-Batch GD is a compromise between GD and SGD, where the model parameters are updated using gradients computed on a small batch of training data rather than the entire dataset.\n",
            "   - Sample code (using TensorFlow):\n",
            "     ```python\n",
            "     optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
            "     for epoch in range(num_epochs):\n",
            "         for i in range(0, num_samples, batch_size):\n",
            "             batch_x = x_train[i:i+batch_size]\n",
            "             batch_y = y_train[i:i+batch_size]\n",
            "             with tf.GradientTape() as tape:\n",
            "                 loss = model(batch_x, batch_y)\n",
            "             gradients = tape.gradient(loss, model.trainable_variables)\n",
            "             optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
            "     ```\n",
            "   - Guidelines: Mini-Batch GD is the most commonly used method as it provides a balance between computation efficiency and convergence stability. The batch size should be chosen based on available memory and computational resources.\n",
            "\n",
            "4. Adam (Adaptive Moment Estimation):\n",
            "   - Description: Adam combines the advantages of AdaGrad and RMSProp optimization methods. It adapts the learning rate for each parameter based on the first and second moments of the gradients.\n",
            "   - Sample code (using TensorFlow):\n",
            "     ```python\n",
            "     optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
            "     with tf.GradientTape() as tape:\n",
            "         loss = model(x_train, y_train)\n",
            "     gradients = tape.gradient(loss, model.trainable_variables)\n",
            "     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
            "     ```\n",
            "   - Guidelines: Adam is a popular choice as it provides fast convergence and works well with default hyperparameters. It is suitable for most neural network architectures and datasets.\n",
            "\n",
            "5. RMSProp (Root Mean Square Propagation):\n",
            "   - Description: RMSProp is an optimization method that adapts the learning rate based on the exponentially weighted average of the squared gradients.\n",
            "   - Sample code (using TensorFlow):\n",
            "     ```python\n",
            "     optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
            "     with tf.GradientTape() as tape:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ya5ejQ7Zh0DT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}